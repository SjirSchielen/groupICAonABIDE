{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "124df4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, csv, time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665d7b43",
   "metadata": {},
   "source": [
    "# Functions for data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0869ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path specifies the root of the folder structure in which the csv files should be\n",
    "# path = r\"C:\\Users\\s169940\\Downloads\\ABIDEgithubtest\\ABIDE\"#\\ABIDE\" #path to the folder in which 'ABIDE_I' and 'ABIDE_II' are located\n",
    "path = r\"C:\\Users\\s169940\\OneDrive - TU Eindhoven\\Documents\\PhD\\data\\ABIDE\\timeSeries\\ABIDE\"\n",
    "pathFD = r\"C:\\Users\\s169940\\Downloads\\ABIDEgithubtest\\supportingFiles\\supportingFiles\\FD.csv\" #location of FD.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f75916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_depth(lst):\n",
    "    #Finds the depth of a list\n",
    "    if isinstance(lst, list):\n",
    "        if not lst: return 1\n",
    "        else: return 1 + max(list_depth(i) for i in lst)\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0c50c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This way of data loading only works if the csv files are placed in a folder named the site (and sample) it is from.\n",
    "#The sites should be placed in a folder corresponding to their ABIDE version.\n",
    "#The motivation behind this is that it matches the file structure as it was downloaded from ABIDE. \n",
    "\n",
    "def obtainCSVs(path):\n",
    "    #recursively iterate through nested folders to find csv files\n",
    "    #as the function returns in the loop, some files should be skipped to avoid breaking the loop\n",
    "    csvFiles = []\n",
    "    for item in os.listdir(path):\n",
    "        itemPath = os.path.join(path, item)\n",
    "        if os.path.isdir(itemPath):\n",
    "            csvFiles.append(obtainCSVs(itemPath))\n",
    "        elif '.csv' in itemPath and 'FD.csv' not in itemPath: \n",
    "            csvFiles.append(itemPath)\n",
    "            return itemPath\n",
    "    return csvFiles\n",
    "\n",
    "def selectSites(csvsA1, csvsA2):\n",
    "    # Apply whitelist. \n",
    "    # This function will not do anything if only the already whitelisted files are present in the folder.\n",
    "    # This was made based on the whole ABIDE dataset, were filtering was necessary according to TR.\n",
    "    whitelistedA1 = [\"Carnegie_Mellon_University\", \"NYU_Langone_Medical_Center\",\n",
    "                     \"San_Diego_State_University\", \"Stanford_University\", \n",
    "                     \"Trinity_Centre_for_Health_Sciences\", \"University_of_Michigan_Sample_1\",\n",
    "                     \"University_of_Michigan_Sample_2\", \"Yale_Child_Study_Center\"]\n",
    "    whitelistedA2 = [\"Erasmus_University_Medical_Center_Rotterdam\", \"Georgetown_University\",\n",
    "                     \"NYU_Langone_Medical_Center_Sample_1\", \"NYU_Langone_Medical_Center_Sample_2\",\n",
    "                     \"San_Diego_State_University\", \"Stanford_University\", \"Trinity_Centre_for_Health_Sciences\",\n",
    "                     \"University_of_California_Davis\", \"University_of_Miami\",\n",
    "                     \"University_of_Utah_School_of_Medicine\"]\n",
    "    \n",
    "    whitelistedPathsA1 = []\n",
    "    for site in whitelistedA1:\n",
    "        whitelistedPathsA1 = whitelistedPathsA1 + [p for p in csvsA1 if site in p]\n",
    "\n",
    "    whitelistedPathsA2 = []\n",
    "    for site in whitelistedA2:\n",
    "        whitelistedPathsA2 = whitelistedPathsA2 + [p for p in csvsA2 if site in p]\n",
    "    return whitelistedPathsA1, whitelistedPathsA2\n",
    "\n",
    "\n",
    "def isColumnEmpty(table, i):\n",
    "    # assumes the first row contains column names\n",
    "    tablenp = np.array(table)\n",
    "    check = all(tablenp[1:, i] == '')\n",
    "    return check\n",
    "\n",
    "def makeTable(path):\n",
    "    #read the csv file and make a table\n",
    "    table = []\n",
    "    with open(path, encoding='ISO-8859-1') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            if len(row) == 1:\n",
    "                row = row[0]\n",
    "                row = row.split(',')\n",
    "            table.append(row)\n",
    "    nonEmptyFields = ([i for i in range(len(table[1])) if not isColumnEmpty(table, i)])\n",
    "    tab = np.array(table)[:, nonEmptyFields] # take out empty fields\n",
    "    version = \"\"\n",
    "    if \"ABIDE_II\" in path: \n",
    "        identifier = path[path.find(\"ABIDEII_\")+len(\"ABIDEII_\"):path.find(\".csv\")]\n",
    "        version = \"ABIDE_II\"\n",
    "    elif \"ABIDE_I\" in path: \n",
    "        identifier = path[::-1][path[::-1].find('.')+1:path[::-1].find('cipytonehp')-1][::-1]\n",
    "        version = \"ABIDE_I\"\n",
    "    identifier = identifier if version == \"\" else version + \", \" + identifier\n",
    "    return tab, identifier\n",
    "\n",
    "def findColumn(tab, title):\n",
    "    #returns the index of the column with the title title in table tab\n",
    "    if title in tab[0]: #row 0 is the title row\n",
    "        colInd = np.where(tab[0] == title)[0]\n",
    "        return int(colInd.item())\n",
    "    else:\n",
    "        print(tab[1][0], \"does not contain field \", title)\n",
    "        return np.nan\n",
    "def obtainColumn(tab, colInd):\n",
    "    #generates a list specifying a column\n",
    "    return [row[colInd] for row in tab]\n",
    "\n",
    "def EmptyField(column):\n",
    "    #checks if the column is filled with entries specifying that it is empty\n",
    "    notspecified = ['', '-9999']\n",
    "    filledOut = [item for item in column[1:] if item not in notspecified]\n",
    "    if len(filledOut) == 0: return True\n",
    "    else: return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b314c2",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f983f0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time [s]:  0.07402443885803223\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "obtainedCSVs = obtainCSVs(path) #obtain csv file paths\n",
    "if list_depth(obtainedCSVs) == 3: obtainedCSVs = obtainedCSVs[0] #it can happen that the 'ABIDE' directory is nested in itself   \n",
    "csvsA1, csvsA2 = obtainedCSVs #if the depth is other than 2, it will cause issues here\n",
    "csvsA1, csvsA2 = selectSites(csvsA1, csvsA2) #select whitelisted \n",
    "end = time.time() - start\n",
    "print(\"Elapsed time [s]: \", end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e5adbd",
   "metadata": {},
   "source": [
    "# Exclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce9ea091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDs to be excluded of CMU_B because of different TR\n",
    "IDs = [50643, 50644, 50645, 50648, 50650, 50651, 50652, 50655, 50657, 50658, 50661, 50667, 50669] \n",
    "excludeIDs = [28861, 28871, 28897, 29495, 29875, 29883, 29885, 30000, 50207,\n",
    "              50286, 50287, 50292, 50299, 50305, 50307, 50317, 50325, 50404,\n",
    "              50647, 50650, 50959, 51163, 51170, 51174] #excluded based on psychoactive medication\n",
    "excludeMotion = True\n",
    "if excludeMotion: #mean FD > 0.5 mm\n",
    "    excludedMotion = [50952,50185,50192,51161,51166,51195,50242,51136,50279,50281,\n",
    "    50296,50303,50304,50306,50308,50309,50311,50313,50323,50354,50359,\n",
    "    50376,50383,50615,50618,29873,29878,29880,29886,29887,29888,29889,29890,29893,\n",
    "    29894,29897,29900,29903,29910,29914,29917,28756,28773,28777,28781,\n",
    "    28784,28799,28812,28818,28819,28823,28831,28832,28834,28839,28840,\n",
    "    30177,29097,29098,29100,29102,29110,29126,29134,29999,30240,30241,\n",
    "    29503,29506,29510,29514]\n",
    "    \n",
    "    excludeIDs = excludeIDs + excludedMotion\n",
    "\n",
    "newExclusions = [50296, 50303, 50308, 50653, 29880, 29887, 29888, 29151,\n",
    "    29152, 29153, 29155, 29156, 29158, 29161, 29167, 29168, 29169, 29171,\n",
    "    29172, 29174, 29175, 29176, 28901, 51167, 51176] #based on visual inspections (i.e. distortions and artifacts, but some were also excluded based on motion)\n",
    "\n",
    "alignmentExclusions = [50642, 50646, 50656, 50665, 50666, 50572, 50603, 50605, 50561]; #not properly normalized to reference space\n",
    "IQexclusions = [50606, 50626]; #PIQ, VIQ, and FIQ under 70\n",
    "excludeIDs = np.unique(excludeIDs + IDs + newExclusions + IQexclusions + alignmentExclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a56288",
   "metadata": {},
   "source": [
    "# Create tables (list of lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e026f949",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabsA1 = [None] * len(csvsA1)\n",
    "identA1 = [None] * len(csvsA1)\n",
    "for i in range(len(csvsA1)):\n",
    "    tabsA1[i], identA1[i] = makeTable(csvsA1[i]) #read csv file into table A1\n",
    "    \n",
    "tabsA2 = [None] * len(csvsA2)\n",
    "identA2 = [None] * len(csvsA2)\n",
    "\n",
    "for i in range(len(csvsA2)):\n",
    "    tabsA2[i], identA2[i] = makeTable(csvsA2[i]) #read csv file into table A2\n",
    "\n",
    "exclusions = []\n",
    "for tabind in range(len(tabsA1)): #take out excluded participants A1\n",
    "    tab = tabsA1[tabind]\n",
    "    subID = findColumn(tab, 'SUB_ID')\n",
    "    IDcol = obtainColumn(tab, subID)\n",
    "    for i in range(len(IDcol)-1, 0, -1):\n",
    "        if int(IDcol[i]) in excludeIDs:\n",
    "            exclusions.append(int(IDcol[i]))\n",
    "            tab = [tab[j] for j in range(len(tab)) if j!=i]\n",
    "            tabsA1[tabind] = tab\n",
    "\n",
    "for tabind in range(len(tabsA2)):  #take out excluded participants A2\n",
    "    tab = tabsA2[tabind]\n",
    "    subID = findColumn(tab, 'SUB_ID')\n",
    "    IDcol = obtainColumn(tab, subID)\n",
    "    for i in range(len(IDcol)-1, 0, -1):\n",
    "        if int(IDcol[i]) in excludeIDs:\n",
    "            exclusions.append(int(IDcol[i]))\n",
    "            tab = [tab[j] for j in range(len(tab)) if j!=i]\n",
    "            tabsA2[tabind] = tab \n",
    "            \n",
    "for tab in tabsA1: #check if excluded IDs still present in tabsA1\n",
    "    subID_col = obtainColumn(tab, findColumn(tab, 'SUB_ID'))\n",
    "    for item in subID_col[1:]:\n",
    "        if int(item) in excludeIDs:\n",
    "            print(\"item:\", item)\n",
    "            \n",
    "for tab in tabsA2: #check if excluded IDs still present in tabsA2\n",
    "    subID_col = obtainColumn(tab, findColumn(tab, 'SUB_ID'))\n",
    "    for item in subID_col[1:]:\n",
    "        if int(item) in excludeIDs:\n",
    "            print(\"item:\", item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb893f8f",
   "metadata": {},
   "source": [
    "# Check for empty columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12d451f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tabind in range(len(tabsA1)): #take out headers for columns with all empty entries\n",
    "    headers = tabsA1[tabind][0]\n",
    "    for i in range(len(headers))[::-1]: #reverse the range to avoid the deleted column causing indexing issues\n",
    "        col = obtainColumn(tabsA1[tabind], i)\n",
    "        if EmptyField(col):\n",
    "            tabsA1[tabind] = [np.delete(row, i) for row in tabsA1[tabind]]\n",
    "\n",
    "for tabind in range(len(tabsA2)): #take out headers for columns with all empty entries\n",
    "    headers = tabsA2[tabind][0]\n",
    "    for i in range(len(headers))[::-1]: #reverse the range to avoid the deleted column causing indexing issues\n",
    "        col = obtainColumn(tabsA2[tabind], i)\n",
    "        if EmptyField(col):\n",
    "            tabsA2[tabind] = [np.delete(row, i) for row in tabsA2[tabind]]\n",
    "            \n",
    "for tab in tabsA1: #check if all empty columns are out\n",
    "    headers = tab[0]\n",
    "    for i in range(len(headers)):\n",
    "        col = obtainColumn(tab, i)\n",
    "        if EmptyField(col):\n",
    "            print(tab[1][0])\n",
    "            print(headers[i])\n",
    "            print(i, len(headers))\n",
    "            \n",
    "for tab in tabsA2: #check if all empty columns are out\n",
    "    headers = tab[0]\n",
    "    for i in range(len(headers)):\n",
    "        col = obtainColumn(tab, i)\n",
    "        if EmptyField(col):\n",
    "            print(tab[1][0])\n",
    "            print(headers[i])\n",
    "            print(i, len(headers))      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096da805",
   "metadata": {},
   "source": [
    "# Class with phenotypic information of participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec17b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class participant:\n",
    "    def __init__(self, dictIn):\n",
    "        # it is possible to extent or change these\n",
    "        self.age = dictIn[\"AGE_AT_SCAN\"]\n",
    "        self.age = dictIn[\"AGE_AT_SCAN \"] if self.age == None else self.age #sometimes there is a space in the column title\n",
    "        if self.age is not None: self.age = float(self.age)\n",
    "        self.site = dictIn[\"SITE_ID\"]\n",
    "        self.partnum = dictIn[\"SUB_ID\"]\n",
    "        self.label = dictIn[\"DX_GROUP\"]\n",
    "        self.diagnosis = \"ASD\" if self.label == 1 else \"HC\"\n",
    "        self.sex = dictIn[\"SEX\"]\n",
    "        self.PIQ = float(dictIn[\"PIQ\"]) if dictIn[\"PIQ\"] is not None else dictIn[\"PIQ\"] \n",
    "        self.FIQ = float(dictIn[\"FIQ\"]) if dictIn[\"FIQ\"] is not None else dictIn[\"FIQ\"]\n",
    "        self.VIQ = float(dictIn[\"VIQ\"]) if dictIn[\"VIQ\"] is not None else dictIn[\"VIQ\"]\n",
    "        self.IQtypes = dict(zip([\"FIQ\", \"VIQ\", \"PIQ\"], [dictIn[\"FIQ_TEST_TYPE\"], dictIn[\"VIQ_TEST_TYPE\"], dictIn[\"PIQ_TEST_TYPE\"]]))\n",
    "        ADOSfields = ['ADOS_MODULE', 'ADOS_RSRCH_RELIABLE', 'ADOS_G_TOTAL', 'ADOS_TOTAL', 'ADOS_G_COMM',\n",
    "                      'ADOS_COMM', 'ADOS_G_SOCIAL','ADOS_SOCIAL', 'ADOS_G_STEREO_BEHAV', 'ADOS_STEREO_BEHAV',\n",
    "                      'ADOS_G_CREATIVITY','ADOS_CREATIVITY', 'ADOS_2_SOCAFFECT', 'ADOS_GOTHAM_SOCAFFECT',\n",
    "                      'ADOS_2_RRB', 'ADOS_GOTHAM_RRB', 'ADOS_2_TOTAL', 'ADOS_GOTHAM_TOTAL', 'ADOS_2_SEVERITY_TOTAL', \n",
    "                      'ADOS_GOTHAM_SEVERITY']\n",
    "#         self.ADOS = dict(zip([\"ADOS_MODULE\", \"ADOS_RSRCH_RELIABLE\"],\n",
    "#                              [dictIn[\"ADOS_MODULE\"], dictIn[\"ADOS_RSRCH_RELIABLE\"]]))\n",
    "        self.ADOS = dict(zip(ADOSfields, [dictIn[f] for f in ADOSfields]))\n",
    "        self.ADIR = dict(zip([\"ADI_R_SOCIAL_TOTAL_A\", \"ADI_R_VERBAL_TOTAL_BV\", \"ADI_R_RRB_TOTAL_C\", \"ADI_R_ONSET_TOTAL_D\", \"ADI_R_RSRCH_RELIABLE\"],\n",
    "                             [dictIn[\"ADI_R_SOCIAL_TOTAL_A\"], dictIn[\"ADI_R_VERBAL_TOTAL_BV\"], dictIn[\"ADI_R_RRB_TOTAL_C\"], dictIn[\"ADI_R_ONSET_TOTAL_D\"], dictIn[\"ADI_R_RSRCH_RELIABLE\"]]))\n",
    "        if self.ADIR['ADI_R_RRB_TOTAL_C'] == None: self.ADIR['ADI_R_RRB_TOTAL_C'] = dictIn[\"ADI_RRB_TOTAL_C\"]\n",
    "        self.DSM_IV_TR = dictIn[\"DSM_IV_TR\"]\n",
    "        self.DSM_IV_TR = dictIn[\"PDD_DSM_IV_TR\"] if self.DSM_IV_TR is None else self.DSM_IV_TR\n",
    "        self.currentMedStatus = dictIn[\"CURRENT_MED_STATUS\"]\n",
    "        self.medName = dictIn[\"MEDICATION_NAME\"]\n",
    "        self.offStimulantsAtScan = dictIn[\"OFF_STIMULANTS_AT_SCAN\"]\n",
    "        self.comorbidity = dictIn[\"COMORBIDITY\"]\n",
    "        self.comorbidity = dictIn[\"NONASD_PSYDX_LABEL\"] if self.comorbidity == None else self.comorbidity\n",
    "        self.comorbidity = None if self.comorbidity == 'none' or self.comorbidity == 'None' else self.comorbidity\n",
    "        self.eyeStatus = dictIn[\"EYE_STATUS_AT_SCAN\"] #1=open, #2=closed\n",
    "        self.handedness = dictIn[\"HANDEDNESS_CATEGORY\"] #1=right handed, 2=left handed, 3=mixed handed\n",
    "        self.setAbideVersion()\n",
    "        \n",
    "    def setAbideVersion(self):\n",
    "        if 'ABIDEII' in self.site: self.abideVersion = 2\n",
    "        else: self.abideVersion = 1\n",
    "            \n",
    "    def __str__(self):\n",
    "        return f\"{self.partnum} {self.site}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0692e4",
   "metadata": {},
   "source": [
    "# Create objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21495494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of participants:  900\n"
     ]
    }
   ],
   "source": [
    "tabs = tabsA1 + tabsA2\n",
    "#it is possible to extent or change these based on the fields in the phenotypic files. Beware that names can differ between\n",
    "# ABIDE I and ABIDE II and sometimes the names have a typo, e.g. 'AGE_AT_SCAN ' should be 'AGE_AT_SCAN'\n",
    "fieldsOfInterest = ['SITE_ID', 'SUB_ID', 'DX_GROUP', 'AGE_AT_SCAN', 'AGE_AT_SCAN ', 'SEX', 'FIQ', 'VIQ', 'PIQ', \n",
    "                   'FIQ_TEST_TYPE', 'VIQ_TEST_TYPE', 'PIQ_TEST_TYPE', 'ADOS_MODULE', 'ADOS_RSRCH_RELIABLE',\n",
    "                    'ADI_R_SOCIAL_TOTAL_A', 'ADI_R_VERBAL_TOTAL_BV', 'ADI_R_RRB_TOTAL_C', 'ADI_RRB_TOTAL_C',\n",
    "                    'ADI_R_ONSET_TOTAL_D',\n",
    "                    'ADI_R_RSRCH_RELIABLE', 'DSM_IV_TR', 'CURRENT_MED_STATUS', 'MEDICATION_NAME',\n",
    "                    'OFF_STIMULANTS_AT_SCAN', 'COMORBIDITY', 'NONASD_PSYDX_LABEL', 'PDD_DSM_IV_TR',\n",
    "                    'ADOS_G_TOTAL', 'ADOS_TOTAL', 'ADOS_G_COMM', 'ADOS_COMM', 'ADOS_G_SOCIAL',\n",
    "                    'ADOS_SOCIAL', 'ADOS_G_STEREO_BEHAV', 'ADOS_STEREO_BEHAV', 'ADOS_G_CREATIVITY',\n",
    "                    'ADOS_CREATIVITY', 'ADOS_2_SOCAFFECT', 'ADOS_GOTHAM_SOCAFFECT', 'ADOS_2_RRB',\n",
    "                    'ADOS_GOTHAM_RRB', 'ADOS_2_TOTAL', 'ADOS_GOTHAM_TOTAL', 'ADOS_2_SEVERITY_TOTAL', \n",
    "                    'ADOS_GOTHAM_SEVERITY', 'HANDEDNESS_CATEGORY', 'EYE_STATUS_AT_SCAN'] \n",
    "participants = []\n",
    "for tab in tabs: #loop through sites\n",
    "    header = tab[0] #header row \n",
    "    for row in tab[1:]: # skip header row for values\n",
    "        itemsForObject = [] #list with values to initialize object\n",
    "        for field in fieldsOfInterest:\n",
    "            fieldInd = np.where(header==field) #obtain index of field\n",
    "            fieldVal = row[fieldInd]           #obtain value at index\n",
    "            if len(fieldVal) == 0: fieldVal = None #if value does not exist, set None\n",
    "            else:                              #read value (it is a string)\n",
    "                fieldVal = fieldVal.item()     \n",
    "                if fieldVal.isnumeric():       #if numeric, parse to float\n",
    "                    fieldVal = float(fieldVal)\n",
    "                    if fieldVal.is_integer(): fieldVal = int(fieldVal) #if float is int, parse to int\n",
    "            if fieldVal == -9999 or fieldVal == '-9999' or fieldVal == '': fieldVal = None #These entries are assumed not specified\n",
    "            itemsForObject.append(fieldVal)\n",
    "        participants.append(participant(dict(zip(fieldsOfInterest,itemsForObject))))\n",
    "\n",
    "print(\"Number of participants: \", len(participants))  #check length\n",
    "# participants is now a list of objects containig patient metadata\n",
    "\n",
    "## read FD information\n",
    "rowcounter = 0\n",
    "rowEntries = []\n",
    "with open(pathFD, 'r') as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in csvreader:\n",
    "        if rowcounter == 0: columnTitles = row #column titles\n",
    "        else: \n",
    "            row[columnTitles.index('ID')] = int(row[columnTitles.index('ID')]) #ID is an int\n",
    "            row[columnTitles.index('mean FD')] = float(row[columnTitles.index('mean FD')]) #mean FD is a float\n",
    "            FDs = row[columnTitles.index('FDs')]\n",
    "            row[columnTitles.index('FDs')] = np.array([float(i) for i in FDs.split(';')]) #parse string to numpy float array\n",
    "            rowEntries.append(row)\n",
    "        rowcounter = rowcounter + 1\n",
    "\n",
    "## insert FD information into objects of participants        \n",
    "for p in participants:\n",
    "    FDrow = [r for r in rowEntries if r[columnTitles.index('ID')] == p.partnum][0] #check if the ID matches\n",
    "    p.FDs = FDrow[columnTitles.index('FDs')] #should all FDs be necessary\n",
    "    p.meanFD = FDrow[columnTitles.index('mean FD')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f598f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMU 50649\n",
      "NYU 50998\n",
      "NYU 51054\n",
      "NYU 51105\n",
      "SDSU 50195\n",
      "STANFORD 51196\n",
      "TRINITY 51142\n",
      "UM_1 50340\n",
      "UM_2 50405\n",
      "YALE 50604\n",
      "ABIDEII-EMC_1 29911\n",
      "ABIDEII-GU_1 28747\n",
      "ABIDEII-NYU_1 29181\n",
      "ABIDEII-NYU_1 29231\n",
      "ABIDEII-SDSU_1 28876\n",
      "ABIDEII-SU_2 30179\n",
      "ABIDEII-TCD_1 29120\n",
      "ABIDEII-U_MIA_1 30233\n"
     ]
    }
   ],
   "source": [
    "#Participants is now a list of objects with fields containing phenotypic data.\n",
    "#Example usage:\n",
    "for p in participants[::50]:\n",
    "    print(p.site, p.partnum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
